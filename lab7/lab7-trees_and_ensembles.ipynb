{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Decision Trees and Ensemble Methods\n",
    "\n",
    "This week we will explore the use of decision trees for simple classification tasks. We will then look at how collections of decision trees (or other machine learning models) can trained on the same dataset and combined to enhance predictive performance. Specifically, we will look at bagging, random forests and boosting which are all related examples of ensemble methods.\n",
    "\n",
    "Before starting, make sure to install the `graphviz` package installed using `conda install python-graphviz`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Decision Trees\n",
    "\n",
    "Decision trees are a very simple machine learning technique that can be surprisingly powerful and offer a much more easily interpretable decision making process than many other methods. As the name suggests, decision trees are comprised of a set of nodes in a tree structure. All non-terminal nodes are called *decision nodes* which typically have two child nodes and contain a conditional expression involving a single feature of the input data. For a given input, starting at the root node, this condition is evaluated and this determines which of the two child nodes are selected for evaluation next. Once a *leaf node* is reached, the decision tree is able to produce an output class (classification) or a target value (regression). In this lab we will focus on the case of classification tasks.\n",
    "\n",
    "For a given dataset of input-output pairs, there are a number of ways to construct a decision tree that can accurately classify the set of examples. We will be using the implementation of decision trees from the scikit-learn library which uses the CART (Classification And Regression Tree) algorithm with the Gini impurity criterion (see [this](https://victorzhou.com/blog/gini-impurity/) for simple explanation of Gini impurity). This algorithm can be summarised as follows:\n",
    "1. **Obtaining the root node**: Test the possible splits of the dataset using conditions involving each of the input features and measure the Gini impurity of each split. The root node is given by the split that minimises the weighted sum of the Gini impurities of the two branches. The weights are equal to the number of data points that satisfy the condition of the corresponding branch.\n",
    "2. **Creating the remaining decision nodes**: Iteratively follow the same process as step 1 using only the data points that match the conditions necessary to reach this point in the tree.\n",
    "3. **Creating the Leaf nodes**: These nodes are created when one of the stopping criteria is met. This set of criteria includes the case where all points of each class have been completely separated by a split (i.e. when the impurity is 0) or when some maximum depth has been reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Training a Decision Tree Classifier\n",
    "\n",
    "To start off, we will load in a classification dataset from scikit-learn: [the famous iris flower dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html#sphx-glr-auto-examples-datasets-plot-iris-dataset-py), compiled by Ronald Fisher in 1936. This is often used as a toy dataset for machine learning and contains three classes (species of Iris) with a number of named features such as petal length and width. The code below loads in the iris dataset but also includes the code to load in several other datasets that you can test your decision tree or ensemble methods on. These are commented out for now but you may wish to explore them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] ; ['setosa' 'versicolor' 'virginica']\n",
      "(150, 4) ; (150,)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]] ; {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_iris()\n",
    "#dataset = datasets.load_wine()\n",
    "#dataset = datasets.load_digits()\n",
    "\n",
    "X = np.array(dataset['data'])\n",
    "X_feature_names = dataset['feature_names']\n",
    "y = np.array(dataset['target'])\n",
    "y_target_names = dataset['target_names']\n",
    "\n",
    "# 60% training, 20% dev and 20% test\n",
    "random.seed(8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = 0.25)\n",
    "\n",
    "print(X_feature_names, \";\", y_target_names)\n",
    "print(X.shape, \";\", y.shape)\n",
    "print(X[:2], \";\", {target for target in y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Training a Decision Tree Classifier\n",
    "\n",
    "Use scikit-learn to train a [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), with the name `model`, on the Iris dataset and compute its accuracy score on both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  1.0\n",
      "Accuracy on test set:  0.9\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: \", model.score(X_train, y_train))\n",
    "print(\"Accuracy on test set: \", model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the model overfitting to the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Visualise the tree\n",
    "\n",
    "The code below has been provided to create a visualisation for your decision tree. This cell will also print out a number of examples from the test set along with your tree's predictions to help you understand how the classification is being made. Run the cell and try to answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 7.0.1 (20221109.1506)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"437pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 437.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-548 433,-548 433,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#fef9f5\" stroke=\"black\" d=\"M197.5,-544C197.5,-544 75.5,-544 75.5,-544 69.5,-544 63.5,-538 63.5,-532 63.5,-532 63.5,-473 63.5,-473 63.5,-467 69.5,-461 75.5,-461 75.5,-461 197.5,-461 197.5,-461 203.5,-461 209.5,-467 209.5,-473 209.5,-473 209.5,-532 209.5,-532 209.5,-538 203.5,-544 197.5,-544\"/>\n<text text-anchor=\"start\" x=\"71.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 0.8</text>\n<text text-anchor=\"start\" x=\"101\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.664</text>\n<text text-anchor=\"start\" x=\"95.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 90</text>\n<text text-anchor=\"start\" x=\"78.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [33, 30, 27]</text>\n<text text-anchor=\"start\" x=\"93\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M105,-417.5C105,-417.5 12,-417.5 12,-417.5 6,-417.5 0,-411.5 0,-405.5 0,-405.5 0,-361.5 0,-361.5 0,-355.5 6,-349.5 12,-349.5 12,-349.5 105,-349.5 105,-349.5 111,-349.5 117,-355.5 117,-361.5 117,-361.5 117,-405.5 117,-405.5 117,-411.5 111,-417.5 105,-417.5\"/>\n<text text-anchor=\"start\" x=\"30.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [33, 0, 0]</text>\n<text text-anchor=\"start\" x=\"15\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109.22,-460.58C102.02,-449.77 94.22,-438.09 86.96,-427.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.04,-425.5 81.58,-419.12 84.22,-429.38 90.04,-425.5\"/>\n<text text-anchor=\"middle\" x=\"75.84\" y=\"-438.68\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ebfcf2\" stroke=\"black\" d=\"M282,-425C282,-425 147,-425 147,-425 141,-425 135,-419 135,-413 135,-413 135,-354 135,-354 135,-348 141,-342 147,-342 147,-342 282,-342 282,-342 288,-342 294,-348 294,-354 294,-354 294,-413 294,-413 294,-419 288,-425 282,-425\"/>\n<text text-anchor=\"start\" x=\"143\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.75</text>\n<text text-anchor=\"start\" x=\"179\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"173.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 57</text>\n<text text-anchor=\"start\" x=\"160\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 30, 27]</text>\n<text text-anchor=\"start\" x=\"162\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.78,-460.58C169.39,-452.16 175.36,-443.2 181.16,-434.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"183.89,-436.72 186.53,-426.46 178.07,-432.84 183.89,-436.72\"/>\n<text text-anchor=\"middle\" x=\"192.27\" y=\"-446.01\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M185,-298.5C185,-298.5 88,-298.5 88,-298.5 82,-298.5 76,-292.5 76,-286.5 76,-286.5 76,-242.5 76,-242.5 76,-236.5 82,-230.5 88,-230.5 88,-230.5 185,-230.5 185,-230.5 191,-230.5 197,-236.5 197,-242.5 197,-242.5 197,-286.5 197,-286.5 197,-292.5 191,-298.5 185,-298.5\"/>\n<text text-anchor=\"start\" x=\"108.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"95.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n<text text-anchor=\"start\" x=\"86\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 28, 0]</text>\n<text text-anchor=\"start\" x=\"84\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M187.22,-341.58C180.02,-330.77 172.22,-319.09 164.96,-308.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"168.04,-306.5 159.58,-300.12 162.22,-310.38 168.04,-306.5\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#8a48e7\" stroke=\"black\" d=\"M357.5,-306C357.5,-306 227.5,-306 227.5,-306 221.5,-306 215.5,-300 215.5,-294 215.5,-294 215.5,-235 215.5,-235 215.5,-229 221.5,-223 227.5,-223 227.5,-223 357.5,-223 357.5,-223 363.5,-223 369.5,-229 369.5,-235 369.5,-235 369.5,-294 369.5,-294 369.5,-300 363.5,-306 357.5,-306\"/>\n<text text-anchor=\"start\" x=\"223.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.75</text>\n<text text-anchor=\"start\" x=\"257\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.128</text>\n<text text-anchor=\"start\" x=\"251.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"242\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 27]</text>\n<text text-anchor=\"start\" x=\"244\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M241.78,-341.58C247.39,-333.16 253.36,-324.2 259.16,-315.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"261.89,-317.72 264.53,-307.46 256.07,-313.84 261.89,-317.72\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M282,-187C282,-187 147,-187 147,-187 141,-187 135,-181 135,-175 135,-175 135,-116 135,-116 135,-110 141,-104 147,-104 147,-104 282,-104 282,-104 288,-104 294,-110 294,-116 294,-116 294,-175 294,-175 294,-181 288,-187 282,-187\"/>\n<text text-anchor=\"start\" x=\"143\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 5.05</text>\n<text text-anchor=\"start\" x=\"186.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"177\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"167.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 2]</text>\n<text text-anchor=\"start\" x=\"162\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M265.22,-222.58C259.61,-214.16 253.64,-205.2 247.84,-196.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"250.93,-194.84 242.47,-188.46 245.11,-198.72 250.93,-194.84\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M417,-179.5C417,-179.5 324,-179.5 324,-179.5 318,-179.5 312,-173.5 312,-167.5 312,-167.5 312,-123.5 312,-123.5 312,-117.5 318,-111.5 324,-111.5 324,-111.5 417,-111.5 417,-111.5 423,-111.5 429,-117.5 429,-123.5 429,-123.5 429,-167.5 429,-167.5 429,-173.5 423,-179.5 417,-179.5\"/>\n<text text-anchor=\"start\" x=\"342.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"329.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"start\" x=\"320\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 25]</text>\n<text text-anchor=\"start\" x=\"322\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 4&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>4&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M319.78,-222.58C326.98,-211.77 334.78,-200.09 342.04,-189.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"344.78,-191.38 347.42,-181.12 338.96,-187.5 344.78,-191.38\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M196,-68C196,-68 99,-68 99,-68 93,-68 87,-62 87,-56 87,-56 87,-12 87,-12 87,-6 93,0 99,0 99,0 196,0 196,0 202,0 208,-6 208,-12 208,-12 208,-56 208,-56 208,-62 202,-68 196,-68\"/>\n<text text-anchor=\"start\" x=\"119.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"110\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"100.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\n<text text-anchor=\"start\" x=\"95\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M189.55,-103.73C184.42,-95.34 179,-86.47 173.81,-78.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.87,-76.29 168.67,-69.59 170.9,-79.95 176.87,-76.29\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M327,-68C327,-68 238,-68 238,-68 232,-68 226,-62 226,-56 226,-56 226,-12 226,-12 226,-6 232,0 238,0 238,0 327,0 327,0 333,0 339,-6 339,-12 339,-12 339,-56 339,-56 339,-62 333,-68 327,-68\"/>\n<text text-anchor=\"start\" x=\"254.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"245\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"235.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\n<text text-anchor=\"start\" x=\"234\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M239.82,-103.73C245.03,-95.34 250.53,-86.47 255.79,-78.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"258.72,-79.93 261.02,-69.59 252.77,-76.23 258.72,-79.93\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.sources.Source at 0x17e149280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) | sepal width (cm)  | petal length (cm) | petal width (cm)  | Label             | Prediction\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "5.0               | 3.6               | 1.4               | 0.2               | setosa            | setosa\n",
      "4.7               | 3.2               | 1.6               | 0.2               | setosa            | setosa\n",
      "5.2               | 3.5               | 1.5               | 0.2               | setosa            | setosa\n",
      "6.9               | 3.1               | 5.1               | 2.3               | virginica         | virginica\n",
      "6.7               | 3.1               | 4.4               | 1.4               | versicolor        | versicolor\n",
      "4.9               | 3.1               | 1.5               | 0.2               | setosa            | setosa\n",
      "5.1               | 3.3               | 1.7               | 0.5               | setosa            | setosa\n",
      "6.7               | 3.0               | 5.2               | 2.3               | virginica         | virginica\n",
      "6.4               | 2.8               | 5.6               | 2.2               | virginica         | virginica\n",
      "6.4               | 2.9               | 4.3               | 1.3               | versicolor        | versicolor\n",
      "6.3               | 3.3               | 4.7               | 1.6               | versicolor        | versicolor\n",
      "4.8               | 3.1               | 1.6               | 0.2               | setosa            | setosa\n",
      "4.9               | 2.5               | 4.5               | 1.7               | virginica         | versicolor\n",
      "7.0               | 3.2               | 4.7               | 1.4               | versicolor        | versicolor\n",
      "6.0               | 2.2               | 5.0               | 1.5               | virginica         | versicolor\n"
     ]
    }
   ],
   "source": [
    "# Visualise the Decision Tree\n",
    "dot_data = sklearn.tree.export_graphviz(model, out_file=None, feature_names=X_feature_names, class_names=y_target_names, filled=True, rounded=True, special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"iris\")\n",
    "display(graph)\n",
    "\n",
    "# Print examples from the test dataset\n",
    "wdth = max([len(name) for name in X_feature_names] + [len(lab) for lab in y_target_names]) + 1\n",
    "print('| '.join([f'{X_feature_names[i]: <{wdth}}' for i in range(len(X_feature_names))] + [f'{\"Label\":<{wdth}}', \"Prediction\"]))\n",
    "print('-'*110)\n",
    "predicted_labels = model.predict(X_test)\n",
    "num_examples = 15\n",
    "for example, label, predicted_label in zip(X_test[:num_examples], y_test[:num_examples], predicted_labels[:num_examples]):\n",
    "    print('| '.join([f'{example[i]: <{wdth}}' for i in range(len(example))] + [f'{y_target_names[label]: <{wdth}}', f'{y_target_names[predicted_label]}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to answer the following questions for your tree (note that taking the left path from a decision node corresponds to the condition in that node being true):\n",
    "1. What features are most informative for identifying the Iris Setosa species and what values must they have? \n",
    "2. What features can be used to discriminate between Iris Virginica and Iris Versicolor if the petals are longer than 4.75cm (hint: look at the paths through the decision tree from root to leaf)?\n",
    "3. Choose one of the examples from the data set and follow the path that would be taken by the decision tree to produce a classification.\n",
    "4. If we had more training data, which decision nodes do you think are most likely to change (hint: look at numbers of samples)?\n",
    "5. Which decision nodes do you think may lead to the most errors if we deploy this model on a new test dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Train a decision tree for MNIST\n",
    "\n",
    "For the iris dataset, we saw that our classifier was able to perform extremely well because of the dataset's simplicity. In this section, we will try to apply a decision tree to a more challenging dataset, the MNIST handwritten digits (as seen in week 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] ['5', '0', '4', '1', '9']\n",
      "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']\n",
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "# load the MNIST data\n",
    "X_mnist, y_mnist = fetch_openml(name='mnist_784',return_X_y=True)\n",
    "random.seed(5)\n",
    "frac_of_dataset = 0.5\n",
    "index = int(frac_of_dataset*X_mnist.shape[0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist.values[:index,:], y_mnist.values[:index], test_size=0.2)\n",
    "\n",
    "print(X_mnist.values[:5], y_mnist.values[:5])\n",
    "print(X_mnist.values.shape, y_mnist.values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like you did before, create and train a decision tree using scikit-learn and using the variable name `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code to train a decision tree classifier here\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Compute the model's accuracy on MNIST train and test sets \n",
    "\n",
    "Compare the performance on train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  1.0\n",
      "Accuracy on test set:  0.851\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "print(\"Accuracy on training set: \", model.score(X_train, y_train))\n",
    "print(\"Accuracy on test set: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the model overfitting on the MNIST data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Bagging\n",
    "The combination of models can often perform much better than the average individual, and sometimes better than the best individual. Ensemble methods are ways of combining multiple models together. For good performance, the models should be diverse to minimise the expected error of the ensemble.\n",
    "\n",
    "Bagging or 'bootstrap aggregation' is a simple ensemble method that induces diversity by training $M$ models on different samples of the training set (with replacement) and combining predictions by taking the mean or majority vote. An approximate bagging algorithm is:\n",
    "1. For $m = 1,...,M$ models:\n",
    "    - Randomly sample $N$ data points with replacement from the training set\n",
    "    - Learn a decision tree (CART algorithm) on the subset of points\n",
    "2. A prediction can be obtained by taking the majority vote over the $M$ model outputs.\n",
    "\n",
    "### 2.1) Train a bagging ensemble\n",
    "\n",
    "Complete the code below to train a bagging ensemble by randomly sampling from the MNIST training dataset to train multiple decision tress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_models = 200\n",
    "sample_size = 2000  # training set size.\n",
    "np.random.seed(0)\n",
    "\n",
    "all_models = []\n",
    "for m in range(num_models):\n",
    "    # TODO\n",
    "    # Sample with replacement from the training set. \n",
    "    # Each sample should contain sample_size data points chosen at random.\n",
    "    # Hint: look at the documentation for numpy.random.choice().\n",
    "\n",
    "    xTrainingSetSelected = []\n",
    "    yTrainingSetSelected = []\n",
    "\n",
    "    for iteration in range(sample_size):\n",
    "        index = np.random.choice(len(X_train))\n",
    "        xTrainingSetSelected.append(X_train[index])\n",
    "        yTrainingSetSelected.append(y_train[index])\n",
    "    \n",
    "    # TODO\n",
    "    # train a decision tree classifier on the random sample.\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    model.fit(xTrainingSetSelected, yTrainingSetSelected)\n",
    "    \n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Implement bagging prediction\n",
    "\n",
    "Complete the `bagging_predict` function and then run the next cell to create predictions from the bagging ensemble based on majority voting of the individual models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many classifiers have voted for each class for each point in the test dataset.\n",
    "def bagging_predict(test_data, all_models):\n",
    "    votes = np.zeros((test_data.shape[0], len(all_models)))  # number of classes = 10.\n",
    "    combined_predictions = np.zeros(test_data.shape[0])\n",
    "\n",
    "    for idx, model in enumerate(all_models):\n",
    "        # TODO\n",
    "        # obtain the predictions from model m for the test data and\n",
    "        # populate the votes vector\n",
    "        votes[:, idx] = model.predict(test_data)\n",
    "        accuracy = np.count_nonzero(votes[:, idx]==int64(y_test))/y_test.shape[0]\n",
    "        print(\"Model {} Test set accuracy: {}\".format(idx, accuracy)) \n",
    "\n",
    "    for test_point in range(votes.shape[0]):\n",
    "        # TODO\n",
    "        # determine the class with the most votes for each test point\n",
    "        # and populate the combined_predictions \n",
    "        # hint use np.bincount\n",
    "        count = np.bincount(votes[test_point].astype(int))\n",
    "        combined_predictions[test_point] = np.where(count == max(count))[0][0]\n",
    "    \n",
    "    return combined_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 Test set accuracy: 0.7135714285714285\n",
      "Model 1 Test set accuracy: 0.7055714285714285\n",
      "Model 2 Test set accuracy: 0.6995714285714286\n",
      "Model 3 Test set accuracy: 0.6935714285714286\n",
      "Model 4 Test set accuracy: 0.713\n",
      "Model 5 Test set accuracy: 0.7094285714285714\n",
      "Model 6 Test set accuracy: 0.7044285714285714\n",
      "Model 7 Test set accuracy: 0.7001428571428572\n",
      "Model 8 Test set accuracy: 0.6978571428571428\n",
      "Model 9 Test set accuracy: 0.7105714285714285\n",
      "Model 10 Test set accuracy: 0.7062857142857143\n",
      "Model 11 Test set accuracy: 0.7301428571428571\n",
      "Model 12 Test set accuracy: 0.6948571428571428\n",
      "Model 13 Test set accuracy: 0.7127142857142857\n",
      "Model 14 Test set accuracy: 0.7062857142857143\n",
      "Model 15 Test set accuracy: 0.7084285714285714\n",
      "Model 16 Test set accuracy: 0.699\n",
      "Model 17 Test set accuracy: 0.7267142857142858\n",
      "Model 18 Test set accuracy: 0.7097142857142857\n",
      "Model 19 Test set accuracy: 0.6942857142857143\n",
      "Model 20 Test set accuracy: 0.7198571428571429\n",
      "Model 21 Test set accuracy: 0.7054285714285714\n",
      "Model 22 Test set accuracy: 0.6957142857142857\n",
      "Model 23 Test set accuracy: 0.698\n",
      "Model 24 Test set accuracy: 0.7195714285714285\n",
      "Model 25 Test set accuracy: 0.7032857142857143\n",
      "Model 26 Test set accuracy: 0.7164285714285714\n",
      "Model 27 Test set accuracy: 0.7021428571428572\n",
      "Model 28 Test set accuracy: 0.7215714285714285\n",
      "Model 29 Test set accuracy: 0.7055714285714285\n",
      "Model 30 Test set accuracy: 0.7044285714285714\n",
      "Model 31 Test set accuracy: 0.7047142857142857\n",
      "Model 32 Test set accuracy: 0.7127142857142857\n",
      "Model 33 Test set accuracy: 0.6937142857142857\n",
      "Model 34 Test set accuracy: 0.7115714285714285\n",
      "Model 35 Test set accuracy: 0.7021428571428572\n",
      "Model 36 Test set accuracy: 0.7091428571428572\n",
      "Model 37 Test set accuracy: 0.6911428571428572\n",
      "Model 38 Test set accuracy: 0.7201428571428572\n",
      "Model 39 Test set accuracy: 0.712\n",
      "Model 40 Test set accuracy: 0.71\n",
      "Model 41 Test set accuracy: 0.6832857142857143\n",
      "Model 42 Test set accuracy: 0.7144285714285714\n",
      "Model 43 Test set accuracy: 0.7295714285714285\n",
      "Model 44 Test set accuracy: 0.7054285714285714\n",
      "Model 45 Test set accuracy: 0.7164285714285714\n",
      "Model 46 Test set accuracy: 0.7137142857142857\n",
      "Model 47 Test set accuracy: 0.7102857142857143\n",
      "Model 48 Test set accuracy: 0.7027142857142857\n",
      "Model 49 Test set accuracy: 0.7097142857142857\n",
      "Model 50 Test set accuracy: 0.6988571428571428\n",
      "Model 51 Test set accuracy: 0.7152857142857143\n",
      "Model 52 Test set accuracy: 0.7148571428571429\n",
      "Model 53 Test set accuracy: 0.7057142857142857\n",
      "Model 54 Test set accuracy: 0.7158571428571429\n",
      "Model 55 Test set accuracy: 0.6952857142857143\n",
      "Model 56 Test set accuracy: 0.7052857142857143\n",
      "Model 57 Test set accuracy: 0.7078571428571429\n",
      "Model 58 Test set accuracy: 0.7138571428571429\n",
      "Model 59 Test set accuracy: 0.6897142857142857\n",
      "Model 60 Test set accuracy: 0.7112857142857143\n",
      "Model 61 Test set accuracy: 0.7012857142857143\n",
      "Model 62 Test set accuracy: 0.6981428571428572\n",
      "Model 63 Test set accuracy: 0.7078571428571429\n",
      "Model 64 Test set accuracy: 0.7257142857142858\n",
      "Model 65 Test set accuracy: 0.702\n",
      "Model 66 Test set accuracy: 0.6958571428571428\n",
      "Model 67 Test set accuracy: 0.7231428571428572\n",
      "Model 68 Test set accuracy: 0.7075714285714285\n",
      "Model 69 Test set accuracy: 0.7078571428571429\n",
      "Model 70 Test set accuracy: 0.6987142857142857\n",
      "Model 71 Test set accuracy: 0.7067142857142857\n",
      "Model 72 Test set accuracy: 0.6947142857142857\n",
      "Model 73 Test set accuracy: 0.6907142857142857\n",
      "Model 74 Test set accuracy: 0.7147142857142857\n",
      "Model 75 Test set accuracy: 0.6937142857142857\n",
      "Model 76 Test set accuracy: 0.709\n",
      "Model 77 Test set accuracy: 0.7115714285714285\n",
      "Model 78 Test set accuracy: 0.7021428571428572\n",
      "Model 79 Test set accuracy: 0.7302857142857143\n",
      "Model 80 Test set accuracy: 0.7147142857142857\n",
      "Model 81 Test set accuracy: 0.7005714285714286\n",
      "Model 82 Test set accuracy: 0.7208571428571429\n",
      "Model 83 Test set accuracy: 0.7085714285714285\n",
      "Model 84 Test set accuracy: 0.6818571428571428\n",
      "Model 85 Test set accuracy: 0.706\n",
      "Model 86 Test set accuracy: 0.7054285714285714\n",
      "Model 87 Test set accuracy: 0.6892857142857143\n",
      "Model 88 Test set accuracy: 0.6931428571428572\n",
      "Model 89 Test set accuracy: 0.709\n",
      "Model 90 Test set accuracy: 0.7014285714285714\n",
      "Model 91 Test set accuracy: 0.7034285714285714\n",
      "Model 92 Test set accuracy: 0.7188571428571429\n",
      "Model 93 Test set accuracy: 0.6947142857142857\n",
      "Model 94 Test set accuracy: 0.7054285714285714\n",
      "Model 95 Test set accuracy: 0.7004285714285714\n",
      "Model 96 Test set accuracy: 0.725\n",
      "Model 97 Test set accuracy: 0.7158571428571429\n",
      "Model 98 Test set accuracy: 0.7067142857142857\n",
      "Model 99 Test set accuracy: 0.7035714285714286\n",
      "Model 100 Test set accuracy: 0.7041428571428572\n",
      "Model 101 Test set accuracy: 0.7015714285714286\n",
      "Model 102 Test set accuracy: 0.7188571428571429\n",
      "Model 103 Test set accuracy: 0.7154285714285714\n",
      "Model 104 Test set accuracy: 0.6888571428571428\n",
      "Model 105 Test set accuracy: 0.6884285714285714\n",
      "Model 106 Test set accuracy: 0.7062857142857143\n",
      "Model 107 Test set accuracy: 0.7141428571428572\n",
      "Model 108 Test set accuracy: 0.706\n",
      "Model 109 Test set accuracy: 0.7034285714285714\n",
      "Model 110 Test set accuracy: 0.7012857142857143\n",
      "Model 111 Test set accuracy: 0.723\n",
      "Model 112 Test set accuracy: 0.6874285714285714\n",
      "Model 113 Test set accuracy: 0.6875714285714286\n",
      "Model 114 Test set accuracy: 0.6957142857142857\n",
      "Model 115 Test set accuracy: 0.7141428571428572\n",
      "Model 116 Test set accuracy: 0.7018571428571428\n",
      "Model 117 Test set accuracy: 0.6992857142857143\n",
      "Model 118 Test set accuracy: 0.6895714285714286\n",
      "Model 119 Test set accuracy: 0.7021428571428572\n",
      "Model 120 Test set accuracy: 0.7001428571428572\n",
      "Model 121 Test set accuracy: 0.7097142857142857\n",
      "Model 122 Test set accuracy: 0.72\n",
      "Model 123 Test set accuracy: 0.7191428571428572\n",
      "Model 124 Test set accuracy: 0.7098571428571429\n",
      "Model 125 Test set accuracy: 0.7084285714285714\n",
      "Model 126 Test set accuracy: 0.6995714285714286\n",
      "Model 127 Test set accuracy: 0.7195714285714285\n",
      "Model 128 Test set accuracy: 0.6927142857142857\n",
      "Model 129 Test set accuracy: 0.6964285714285714\n",
      "Model 130 Test set accuracy: 0.694\n",
      "Model 131 Test set accuracy: 0.7068571428571429\n",
      "Model 132 Test set accuracy: 0.7094285714285714\n",
      "Model 133 Test set accuracy: 0.7141428571428572\n",
      "Model 134 Test set accuracy: 0.7042857142857143\n",
      "Model 135 Test set accuracy: 0.7\n",
      "Model 136 Test set accuracy: 0.698\n",
      "Model 137 Test set accuracy: 0.6902857142857143\n",
      "Model 138 Test set accuracy: 0.7151428571428572\n",
      "Model 139 Test set accuracy: 0.7105714285714285\n",
      "Model 140 Test set accuracy: 0.7114285714285714\n",
      "Model 141 Test set accuracy: 0.7107142857142857\n",
      "Model 142 Test set accuracy: 0.6955714285714286\n",
      "Model 143 Test set accuracy: 0.7172857142857143\n",
      "Model 144 Test set accuracy: 0.7105714285714285\n",
      "Model 145 Test set accuracy: 0.7107142857142857\n",
      "Model 146 Test set accuracy: 0.6958571428571428\n",
      "Model 147 Test set accuracy: 0.7028571428571428\n",
      "Model 148 Test set accuracy: 0.7085714285714285\n",
      "Model 149 Test set accuracy: 0.7134285714285714\n",
      "Model 150 Test set accuracy: 0.7054285714285714\n",
      "Model 151 Test set accuracy: 0.7078571428571429\n",
      "Model 152 Test set accuracy: 0.6991428571428572\n",
      "Model 153 Test set accuracy: 0.7055714285714285\n",
      "Model 154 Test set accuracy: 0.6915714285714286\n",
      "Model 155 Test set accuracy: 0.7107142857142857\n",
      "Model 156 Test set accuracy: 0.7224285714285714\n",
      "Model 157 Test set accuracy: 0.722\n",
      "Model 158 Test set accuracy: 0.6988571428571428\n",
      "Model 159 Test set accuracy: 0.702\n",
      "Model 160 Test set accuracy: 0.7094285714285714\n",
      "Model 161 Test set accuracy: 0.7098571428571429\n",
      "Model 162 Test set accuracy: 0.6845714285714286\n",
      "Model 163 Test set accuracy: 0.7002857142857143\n",
      "Model 164 Test set accuracy: 0.7175714285714285\n",
      "Model 165 Test set accuracy: 0.7201428571428572\n",
      "Model 166 Test set accuracy: 0.7\n",
      "Model 167 Test set accuracy: 0.7222857142857143\n",
      "Model 168 Test set accuracy: 0.6954285714285714\n",
      "Model 169 Test set accuracy: 0.6981428571428572\n",
      "Model 170 Test set accuracy: 0.7018571428571428\n",
      "Model 171 Test set accuracy: 0.7352857142857143\n",
      "Model 172 Test set accuracy: 0.7112857142857143\n",
      "Model 173 Test set accuracy: 0.7002857142857143\n",
      "Model 174 Test set accuracy: 0.7058571428571428\n",
      "Model 175 Test set accuracy: 0.7137142857142857\n",
      "Model 176 Test set accuracy: 0.6925714285714286\n",
      "Model 177 Test set accuracy: 0.725\n",
      "Model 178 Test set accuracy: 0.7205714285714285\n",
      "Model 179 Test set accuracy: 0.6985714285714286\n",
      "Model 180 Test set accuracy: 0.6892857142857143\n",
      "Model 181 Test set accuracy: 0.6995714285714286\n",
      "Model 182 Test set accuracy: 0.7007142857142857\n",
      "Model 183 Test set accuracy: 0.7141428571428572\n",
      "Model 184 Test set accuracy: 0.707\n",
      "Model 185 Test set accuracy: 0.7038571428571428\n",
      "Model 186 Test set accuracy: 0.7244285714285714\n",
      "Model 187 Test set accuracy: 0.7007142857142857\n",
      "Model 188 Test set accuracy: 0.7008571428571428\n",
      "Model 189 Test set accuracy: 0.7157142857142857\n",
      "Model 190 Test set accuracy: 0.7065714285714285\n",
      "Model 191 Test set accuracy: 0.7137142857142857\n",
      "Model 192 Test set accuracy: 0.7032857142857143\n",
      "Model 193 Test set accuracy: 0.7098571428571429\n",
      "Model 194 Test set accuracy: 0.7037142857142857\n",
      "Model 195 Test set accuracy: 0.7111428571428572\n",
      "Model 196 Test set accuracy: 0.718\n",
      "Model 197 Test set accuracy: 0.7258571428571429\n",
      "Model 198 Test set accuracy: 0.6981428571428572\n",
      "Model 199 Test set accuracy: 0.7071428571428572\n",
      "Test set accuracy: 0.9237142857142857\n"
     ]
    }
   ],
   "source": [
    "prediction = bagging_predict(X_test, all_models)\n",
    "accuracy = np.count_nonzero(prediction==int64(y_test))/y_test.shape[0]\n",
    "print(\"Test set accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the accuracy compare to a single decision tree? \n",
    "\n",
    "Investigate the effect of changing the `sample_size` and `num_models` hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Random Forests\n",
    "With bagging, the base models (individual decision trees) make similar splits on the same features, meaning that their errors are correlated and this reduces the diversity of the ensemble and limits performance.\n",
    "\n",
    "Random forests improve the diversity of the base models by limiting the number of features considered for determining each split in the decision tree. We can obtain the random forest by modifying the bagging algorithm above so that each split for each model uses only a random subset of features.\n",
    "\n",
    "### 3.1) Implement Random Forest Training\n",
    "\n",
    "Copy in your code for the bagging procedure and modify it to implement random forest. The outline code below shows you where to make the modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 200\n",
    "sample_size = 2000  # training set size.\n",
    "feature_sample_size = 200\n",
    "np.random.seed(0)\n",
    "\n",
    "all_models = []\n",
    "for m in range(num_models):\n",
    "    all_selected_features = []  # for each model, save the list of selected feature indexes.\n",
    "\n",
    "    # TODO\n",
    "    # copy in your code from the bagging exercise here to sample with replacement from the training set. \n",
    "    # Each sample should contain sample_size data points chosen at random.\n",
    "    # Hint: look at the documentation for numpy.random.choice().\n",
    "    X_train_sample = []\n",
    "    y_train_sample = []\n",
    "\n",
    "    for iteration in range(sample_size):\n",
    "        index = np.random.choice(len(X_train))\n",
    "        X_train_sample.append(X_train[index])\n",
    "        y_train_sample.append(y_train[index])\n",
    "\n",
    "    # TODO\n",
    "    # create a decision tree classifier with limited features considered\n",
    "    # for each split\n",
    "    \"\"\" all_selected_features = np.random.choice(X_mnist.values.shape[1], replace=False, size=feature_sample_size)\n",
    "    X_train_sample = np.array(X_train_sample)[:, all_selected_features] \"\"\"\n",
    "    model = DecisionTreeClassifier(random_state=0, max_features=feature_sample_size)\n",
    "    \n",
    "    # TODO\n",
    "    # copy in your code from the bagging exercise here to train a decision tree classifier on the random sample.\n",
    "    # Remember to train it only on the random sample of features.\n",
    "    model.fit(X_train_sample, y_train_sample)\n",
    "    \n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Random Forest Prediction\n",
    "\n",
    "Use the `bagging_predict` function from Section 2.2 to generate predictions for the random forest and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 Test set accuracy: 0.7091428571428572\n",
      "Model 1 Test set accuracy: 0.7031428571428572\n",
      "Model 2 Test set accuracy: 0.6862857142857143\n",
      "Model 3 Test set accuracy: 0.6898571428571428\n",
      "Model 4 Test set accuracy: 0.698\n",
      "Model 5 Test set accuracy: 0.696\n",
      "Model 6 Test set accuracy: 0.693\n",
      "Model 7 Test set accuracy: 0.6894285714285714\n",
      "Model 8 Test set accuracy: 0.6942857142857143\n",
      "Model 9 Test set accuracy: 0.6957142857142857\n",
      "Model 10 Test set accuracy: 0.6875714285714286\n",
      "Model 11 Test set accuracy: 0.6948571428571428\n",
      "Model 12 Test set accuracy: 0.6898571428571428\n",
      "Model 13 Test set accuracy: 0.7035714285714286\n",
      "Model 14 Test set accuracy: 0.7014285714285714\n",
      "Model 15 Test set accuracy: 0.6842857142857143\n",
      "Model 16 Test set accuracy: 0.701\n",
      "Model 17 Test set accuracy: 0.6735714285714286\n",
      "Model 18 Test set accuracy: 0.7085714285714285\n",
      "Model 19 Test set accuracy: 0.6912857142857143\n",
      "Model 20 Test set accuracy: 0.7085714285714285\n",
      "Model 21 Test set accuracy: 0.703\n",
      "Model 22 Test set accuracy: 0.6935714285714286\n",
      "Model 23 Test set accuracy: 0.6955714285714286\n",
      "Model 24 Test set accuracy: 0.7015714285714286\n",
      "Model 25 Test set accuracy: 0.6978571428571428\n",
      "Model 26 Test set accuracy: 0.6974285714285714\n",
      "Model 27 Test set accuracy: 0.7012857142857143\n",
      "Model 28 Test set accuracy: 0.6957142857142857\n",
      "Model 29 Test set accuracy: 0.6921428571428572\n",
      "Model 30 Test set accuracy: 0.6972857142857143\n",
      "Model 31 Test set accuracy: 0.7077142857142857\n",
      "Model 32 Test set accuracy: 0.691\n",
      "Model 33 Test set accuracy: 0.693\n",
      "Model 34 Test set accuracy: 0.6964285714285714\n",
      "Model 35 Test set accuracy: 0.7054285714285714\n",
      "Model 36 Test set accuracy: 0.6932857142857143\n",
      "Model 37 Test set accuracy: 0.6842857142857143\n",
      "Model 38 Test set accuracy: 0.6791428571428572\n",
      "Model 39 Test set accuracy: 0.7108571428571429\n",
      "Model 40 Test set accuracy: 0.6902857142857143\n",
      "Model 41 Test set accuracy: 0.6871428571428572\n",
      "Model 42 Test set accuracy: 0.6758571428571428\n",
      "Model 43 Test set accuracy: 0.7164285714285714\n",
      "Model 44 Test set accuracy: 0.7067142857142857\n",
      "Model 45 Test set accuracy: 0.7102857142857143\n",
      "Model 46 Test set accuracy: 0.7121428571428572\n",
      "Model 47 Test set accuracy: 0.6712857142857143\n",
      "Model 48 Test set accuracy: 0.6872857142857143\n",
      "Model 49 Test set accuracy: 0.691\n",
      "Model 50 Test set accuracy: 0.7062857142857143\n",
      "Model 51 Test set accuracy: 0.7032857142857143\n",
      "Model 52 Test set accuracy: 0.7092857142857143\n",
      "Model 53 Test set accuracy: 0.704\n",
      "Model 54 Test set accuracy: 0.695\n",
      "Model 55 Test set accuracy: 0.691\n",
      "Model 56 Test set accuracy: 0.6964285714285714\n",
      "Model 57 Test set accuracy: 0.6987142857142857\n",
      "Model 58 Test set accuracy: 0.696\n",
      "Model 59 Test set accuracy: 0.6854285714285714\n",
      "Model 60 Test set accuracy: 0.718\n",
      "Model 61 Test set accuracy: 0.6918571428571428\n",
      "Model 62 Test set accuracy: 0.6935714285714286\n",
      "Model 63 Test set accuracy: 0.6952857142857143\n",
      "Model 64 Test set accuracy: 0.7085714285714285\n",
      "Model 65 Test set accuracy: 0.7115714285714285\n",
      "Model 66 Test set accuracy: 0.7027142857142857\n",
      "Model 67 Test set accuracy: 0.6818571428571428\n",
      "Model 68 Test set accuracy: 0.7092857142857143\n",
      "Model 69 Test set accuracy: 0.7052857142857143\n",
      "Model 70 Test set accuracy: 0.6841428571428572\n",
      "Model 71 Test set accuracy: 0.6934285714285714\n",
      "Model 72 Test set accuracy: 0.6894285714285714\n",
      "Model 73 Test set accuracy: 0.7047142857142857\n",
      "Model 74 Test set accuracy: 0.6951428571428572\n",
      "Model 75 Test set accuracy: 0.7034285714285714\n",
      "Model 76 Test set accuracy: 0.6995714285714286\n",
      "Model 77 Test set accuracy: 0.6977142857142857\n",
      "Model 78 Test set accuracy: 0.6865714285714286\n",
      "Model 79 Test set accuracy: 0.6967142857142857\n",
      "Model 80 Test set accuracy: 0.6927142857142857\n",
      "Model 81 Test set accuracy: 0.6928571428571428\n",
      "Model 82 Test set accuracy: 0.6925714285714286\n",
      "Model 83 Test set accuracy: 0.6862857142857143\n",
      "Model 84 Test set accuracy: 0.6871428571428572\n",
      "Model 85 Test set accuracy: 0.6925714285714286\n",
      "Model 86 Test set accuracy: 0.707\n",
      "Model 87 Test set accuracy: 0.7068571428571429\n",
      "Model 88 Test set accuracy: 0.7135714285714285\n",
      "Model 89 Test set accuracy: 0.7044285714285714\n",
      "Model 90 Test set accuracy: 0.6905714285714286\n",
      "Model 91 Test set accuracy: 0.6982857142857143\n",
      "Model 92 Test set accuracy: 0.7008571428571428\n",
      "Model 93 Test set accuracy: 0.7164285714285714\n",
      "Model 94 Test set accuracy: 0.6878571428571428\n",
      "Model 95 Test set accuracy: 0.6991428571428572\n",
      "Model 96 Test set accuracy: 0.7117142857142857\n",
      "Model 97 Test set accuracy: 0.6827142857142857\n",
      "Model 98 Test set accuracy: 0.7042857142857143\n",
      "Model 99 Test set accuracy: 0.6971428571428572\n",
      "Model 100 Test set accuracy: 0.7078571428571429\n",
      "Model 101 Test set accuracy: 0.6962857142857143\n",
      "Model 102 Test set accuracy: 0.6897142857142857\n",
      "Model 103 Test set accuracy: 0.7138571428571429\n",
      "Model 104 Test set accuracy: 0.6957142857142857\n",
      "Model 105 Test set accuracy: 0.7091428571428572\n",
      "Model 106 Test set accuracy: 0.6987142857142857\n",
      "Model 107 Test set accuracy: 0.7004285714285714\n",
      "Model 108 Test set accuracy: 0.6881428571428572\n",
      "Model 109 Test set accuracy: 0.6985714285714286\n",
      "Model 110 Test set accuracy: 0.7168571428571429\n",
      "Model 111 Test set accuracy: 0.7152857142857143\n",
      "Model 112 Test set accuracy: 0.6938571428571428\n",
      "Model 113 Test set accuracy: 0.7094285714285714\n",
      "Model 114 Test set accuracy: 0.6832857142857143\n",
      "Model 115 Test set accuracy: 0.7035714285714286\n",
      "Model 116 Test set accuracy: 0.7065714285714285\n",
      "Model 117 Test set accuracy: 0.6767142857142857\n",
      "Model 118 Test set accuracy: 0.6898571428571428\n",
      "Model 119 Test set accuracy: 0.7008571428571428\n",
      "Model 120 Test set accuracy: 0.6915714285714286\n",
      "Model 121 Test set accuracy: 0.685\n",
      "Model 122 Test set accuracy: 0.7081428571428572\n",
      "Model 123 Test set accuracy: 0.6985714285714286\n",
      "Model 124 Test set accuracy: 0.6782857142857143\n",
      "Model 125 Test set accuracy: 0.703\n",
      "Model 126 Test set accuracy: 0.6707142857142857\n",
      "Model 127 Test set accuracy: 0.691\n",
      "Model 128 Test set accuracy: 0.7027142857142857\n",
      "Model 129 Test set accuracy: 0.6865714285714286\n",
      "Model 130 Test set accuracy: 0.708\n",
      "Model 131 Test set accuracy: 0.7021428571428572\n",
      "Model 132 Test set accuracy: 0.7078571428571429\n",
      "Model 133 Test set accuracy: 0.6882857142857143\n",
      "Model 134 Test set accuracy: 0.6864285714285714\n",
      "Model 135 Test set accuracy: 0.7038571428571428\n",
      "Model 136 Test set accuracy: 0.699\n",
      "Model 137 Test set accuracy: 0.7058571428571428\n",
      "Model 138 Test set accuracy: 0.7098571428571429\n",
      "Model 139 Test set accuracy: 0.6878571428571428\n",
      "Model 140 Test set accuracy: 0.7094285714285714\n",
      "Model 141 Test set accuracy: 0.7042857142857143\n",
      "Model 142 Test set accuracy: 0.706\n",
      "Model 143 Test set accuracy: 0.6857142857142857\n",
      "Model 144 Test set accuracy: 0.6922857142857143\n",
      "Model 145 Test set accuracy: 0.7044285714285714\n",
      "Model 146 Test set accuracy: 0.6967142857142857\n",
      "Model 147 Test set accuracy: 0.6928571428571428\n",
      "Model 148 Test set accuracy: 0.7167142857142857\n",
      "Model 149 Test set accuracy: 0.7012857142857143\n",
      "Model 150 Test set accuracy: 0.6891428571428572\n",
      "Model 151 Test set accuracy: 0.6871428571428572\n",
      "Model 152 Test set accuracy: 0.6838571428571428\n",
      "Model 153 Test set accuracy: 0.6737142857142857\n",
      "Model 154 Test set accuracy: 0.6932857142857143\n",
      "Model 155 Test set accuracy: 0.7184285714285714\n",
      "Model 156 Test set accuracy: 0.7041428571428572\n",
      "Model 157 Test set accuracy: 0.6895714285714286\n",
      "Model 158 Test set accuracy: 0.679\n",
      "Model 159 Test set accuracy: 0.6865714285714286\n",
      "Model 160 Test set accuracy: 0.7061428571428572\n",
      "Model 161 Test set accuracy: 0.6871428571428572\n",
      "Model 162 Test set accuracy: 0.7022857142857143\n",
      "Model 163 Test set accuracy: 0.6884285714285714\n",
      "Model 164 Test set accuracy: 0.7042857142857143\n",
      "Model 165 Test set accuracy: 0.7124285714285714\n",
      "Model 166 Test set accuracy: 0.7087142857142857\n",
      "Model 167 Test set accuracy: 0.6891428571428572\n",
      "Model 168 Test set accuracy: 0.6974285714285714\n",
      "Model 169 Test set accuracy: 0.6738571428571428\n",
      "Model 170 Test set accuracy: 0.6908571428571428\n",
      "Model 171 Test set accuracy: 0.7061428571428572\n",
      "Model 172 Test set accuracy: 0.6968571428571428\n",
      "Model 173 Test set accuracy: 0.69\n",
      "Model 174 Test set accuracy: 0.6938571428571428\n",
      "Model 175 Test set accuracy: 0.7091428571428572\n",
      "Model 176 Test set accuracy: 0.684\n",
      "Model 177 Test set accuracy: 0.7038571428571428\n",
      "Model 178 Test set accuracy: 0.7037142857142857\n",
      "Model 179 Test set accuracy: 0.7008571428571428\n",
      "Model 180 Test set accuracy: 0.6898571428571428\n",
      "Model 181 Test set accuracy: 0.692\n",
      "Model 182 Test set accuracy: 0.6995714285714286\n",
      "Model 183 Test set accuracy: 0.6911428571428572\n",
      "Model 184 Test set accuracy: 0.7048571428571428\n",
      "Model 185 Test set accuracy: 0.6855714285714286\n",
      "Model 186 Test set accuracy: 0.703\n",
      "Model 187 Test set accuracy: 0.7104285714285714\n",
      "Model 188 Test set accuracy: 0.7177142857142857\n",
      "Model 189 Test set accuracy: 0.6994285714285714\n",
      "Model 190 Test set accuracy: 0.6988571428571428\n",
      "Model 191 Test set accuracy: 0.7015714285714286\n",
      "Model 192 Test set accuracy: 0.7002857142857143\n",
      "Model 193 Test set accuracy: 0.6861428571428572\n",
      "Model 194 Test set accuracy: 0.7051428571428572\n",
      "Model 195 Test set accuracy: 0.6928571428571428\n",
      "Model 196 Test set accuracy: 0.6981428571428572\n",
      "Model 197 Test set accuracy: 0.7004285714285714\n",
      "Model 198 Test set accuracy: 0.6828571428571428\n",
      "Model 199 Test set accuracy: 0.6924285714285714\n",
      "Test set accuracy: 0.9308571428571428\n"
     ]
    }
   ],
   "source": [
    "prediction = bagging_predict(X_test, all_models)\n",
    "accuracy = np.count_nonzero(prediction==int64(y_test))/y_test.shape[0]\n",
    "print(\"Test set accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the performance of the random forest compare to bagging and the single model? Can you improve the performance by changing the hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Boosting\n",
    "We can use a decision tree classifier as the base model for the ensemble method known as boosting. Boosting involves training base models in sequence to ensure that each base model addresses the weaknesses of the ensemble. Instead of training a new base model on a random sample, we weight the data points in the training set according to the performance of previous base models.\n",
    "\n",
    "AdaBoost (adaptive boosting) is a popular boosting method, where training examples that are misclassified by one of the base classifiers are given greater weight when used to train the next classifier in the sequence. Once all the classifiers have been trained, their predictions are then combined through a weighted majority voting scheme.\n",
    "\n",
    "The AdaBoost algorithm which you will implement is given below:\n",
    "1. Initialize the data weighting coefficients $w_n$ by setting $w_n^{(1)} = 1/N$ for $ n = 1,...,N$ where $N$ is the number of training examples\n",
    "2. For $m = 1,...,M$ models:\n",
    "    - Fit a classifier $y_m(x)$ to a subset of the training data by minimising the weighted error function (hint: specify the `sample_weight` when fitting the model using scikit-learn).\n",
    "    - Calculate the weighted error, $\\epsilon_m$, where \n",
    "    $$\\epsilon_m = 1 - {weightedAccuracy} = 1 - \\frac{\\sum_{n=1}^N{w_nI(y_m(x_n) = t_n)}}{\\sum_{n=1}^N{w_n}}$$\n",
    "    \n",
    "    $$\\epsilon_m = 1 - \\text{weighted_accuracy} = 1 - \\frac{\\sum_{n=1}^N{w_nI(y_m(x_n) = t_n)}}{\\sum_{n=1}^N{w_n}}$$\n",
    "    and $I$ is the indicator function that equals $1$ when the condition is true (hint: the computation for the weighted accuracy is done for you if `sample_weight` is specified when calling the [`score`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.score) function).\n",
    "    - Calculate the model weighting coefficients, $\\alpha_m$, where\n",
    "    $$\\alpha_m = ln\\left(\\frac{1-\\epsilon_m}{\\epsilon_m}\\right)$$\n",
    "    - Update the data weighting coefficients\n",
    "    $w_n^{(m+1)} = w_n^{(m)} exp(\\alpha_m \\space I(y_m(x_n) \\neq t_n))$ where, again, $I$ is the indicator function.\n",
    "    \n",
    "    $$w_n^{(m+1)} = w_n^{(m)} exp(\\alpha_m \\space I(y_m(x_n) \\neq t_n))$$ where, again, $I$ is the indicator function.\n",
    "3. The final prediction is a weighted combination of the trained base classifiers weighted by $\\alpha_m$.\n",
    "    \n",
    "For more information on boosting, see Bishop section 14.3.\n",
    "\n",
    "### 4.1) Train an ensemble model using the AdaBoost algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 200 # number of base classifiers\n",
    "sample_size = 2000  # sample training set size.\n",
    "np.random.seed(0)\n",
    "\n",
    "# TODO\n",
    "# initialise the sample weights for all data points in the training set.\n",
    "initialWeight = 1.0/sample_size\n",
    "sampleWeights = np.full(sample_size, initialWeight)\n",
    "\n",
    "alphas = []\n",
    "all_models = []\n",
    "for m in range(num_models):\n",
    "    # TODO\n",
    "    # copy in your code from the bagging exercise here to sample with replacement from the training set. \n",
    "    # Each sample should contain sample_size data points chosen at random.\n",
    "    # Hint: look at the documentation for numpy.random.choice().\n",
    "    X_train_sample = []\n",
    "    y_train_sample = []\n",
    "\n",
    "    for iteration in range(sample_size):\n",
    "        index = np.random.choice(len(X_train))\n",
    "        X_train_sample.append(X_train[index])\n",
    "        y_train_sample.append(y_train[index])\n",
    "    \n",
    "    # TODO\n",
    "    # train a decision tree classifier on the weighted random sample.\n",
    "    # Consider setting the max_depth hyperparameter\n",
    "    # Hint: fit() takes an additional argument, 'sample_weight'.\n",
    "    model = DecisionTreeClassifier(random_state=0, max_depth=10)\n",
    "    model.fit(X_train_sample, y_train_sample, sample_weight=sampleWeights)\n",
    "    \n",
    "    # TODO\n",
    "    # compute the model error using weighted accuracy for the sampled training dataset\n",
    "    # Hint: score() score takes an additional argument, 'sample_weight'.\n",
    "    weightedError = 1 - model.score(X_train_sample, y_train_sample, sample_weight=sampleWeights)\n",
    "    \n",
    "    # TODO\n",
    "    # calculate alpha for the model and append alpha to alphas\n",
    "    modelWeightingCoefficients = np.log((1 - weightedError) / weightedError)\n",
    "    alphas.append(modelWeightingCoefficients)\n",
    "    \n",
    "    # TODO\n",
    "    # update the sample_weights for incorrect predictions using alpha\n",
    "    for iteration in range(sample_size):\n",
    "        sampleWeights[iteration] = sampleWeights[iteration] * np.exp(modelWeightingCoefficients * (model.predict(X_train_sample[iteration].reshape(1, -1)) != y_train_sample[iteration]))\n",
    "    \n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Adaboost prediction\n",
    "Complete the `boosting_predict` function to produce predictions from the trained models. In addition to the test data and the trained models, the function also takes the list of $\\alpha_m$ as an input which determines the weighting of each individual model on the overall output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting_predict(test_data, all_models, alphas):\n",
    "    votes = np.zeros((test_data.shape[0], len(all_models))) \n",
    "    combined_predictions = np.zeros(test_data.shape[0])\n",
    "\n",
    "    for idx, model in enumerate(all_models):\n",
    "        # TODO\n",
    "        # write your code here to obtain the predictions from model m and store it in votes.\n",
    "        votes[:, idx] = model.predict(test_data)\n",
    "        accuracy = np.count_nonzero(votes[:, idx]==int64(y_test))/y_test.shape[0]\n",
    "        print(\"Model {} Test set accuracy: {}\".format(idx, accuracy)) \n",
    "    \n",
    "    for test_point in range(len(votes)):\n",
    "        # TODO\n",
    "        # determine the class with the most votes for each test point and store it in combined_predictions\n",
    "        # hint: remember the weighting alpha\n",
    "        count = np.bincount(votes[test_point].astype(int), weights=alphas)\n",
    "        combined_predictions[test_point] = np.where(count == max(count))[0][0]\n",
    "    \n",
    "    return combined_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 Test set accuracy: 0.7104285714285714\n",
      "Model 1 Test set accuracy: 0.6912857142857143\n",
      "Model 2 Test set accuracy: 0.6675714285714286\n",
      "Model 3 Test set accuracy: 0.6574285714285715\n",
      "Model 4 Test set accuracy: 0.653\n",
      "Model 5 Test set accuracy: 0.6395714285714286\n",
      "Model 6 Test set accuracy: 0.5977142857142858\n",
      "Model 7 Test set accuracy: 0.6594285714285715\n",
      "Model 8 Test set accuracy: 0.6497142857142857\n",
      "Model 9 Test set accuracy: 0.6491428571428571\n",
      "Model 10 Test set accuracy: 0.5924285714285714\n",
      "Model 11 Test set accuracy: 0.6687142857142857\n",
      "Model 12 Test set accuracy: 0.621\n",
      "Model 13 Test set accuracy: 0.5704285714285714\n",
      "Model 14 Test set accuracy: 0.6431428571428571\n",
      "Model 15 Test set accuracy: 0.6121428571428571\n",
      "Model 16 Test set accuracy: 0.544\n",
      "Model 17 Test set accuracy: 0.6157142857142858\n",
      "Model 18 Test set accuracy: 0.6307142857142857\n",
      "Model 19 Test set accuracy: 0.646\n",
      "Model 20 Test set accuracy: 0.5935714285714285\n",
      "Model 21 Test set accuracy: 0.5922857142857143\n",
      "Model 22 Test set accuracy: 0.622\n",
      "Model 23 Test set accuracy: 0.64\n",
      "Model 24 Test set accuracy: 0.6467142857142857\n",
      "Model 25 Test set accuracy: 0.5965714285714285\n",
      "Model 26 Test set accuracy: 0.5814285714285714\n",
      "Model 27 Test set accuracy: 0.5645714285714286\n",
      "Model 28 Test set accuracy: 0.5808571428571428\n",
      "Model 29 Test set accuracy: 0.6271428571428571\n",
      "Model 30 Test set accuracy: 0.5827142857142857\n",
      "Model 31 Test set accuracy: 0.537\n",
      "Model 32 Test set accuracy: 0.6004285714285714\n",
      "Model 33 Test set accuracy: 0.6221428571428571\n",
      "Model 34 Test set accuracy: 0.6178571428571429\n",
      "Model 35 Test set accuracy: 0.6067142857142858\n",
      "Model 36 Test set accuracy: 0.6431428571428571\n",
      "Model 37 Test set accuracy: 0.6351428571428571\n",
      "Model 38 Test set accuracy: 0.6214285714285714\n",
      "Model 39 Test set accuracy: 0.5522857142857143\n",
      "Model 40 Test set accuracy: 0.6012857142857143\n",
      "Model 41 Test set accuracy: 0.6028571428571429\n",
      "Model 42 Test set accuracy: 0.6062857142857143\n",
      "Model 43 Test set accuracy: 0.6352857142857142\n",
      "Model 44 Test set accuracy: 0.6224285714285714\n",
      "Model 45 Test set accuracy: 0.5827142857142857\n",
      "Model 46 Test set accuracy: 0.5821428571428572\n",
      "Model 47 Test set accuracy: 0.5354285714285715\n",
      "Model 48 Test set accuracy: 0.6238571428571429\n",
      "Model 49 Test set accuracy: 0.5965714285714285\n",
      "Model 50 Test set accuracy: 0.578\n",
      "Model 51 Test set accuracy: 0.5771428571428572\n",
      "Model 52 Test set accuracy: 0.6455714285714286\n",
      "Model 53 Test set accuracy: 0.6105714285714285\n",
      "Model 54 Test set accuracy: 0.5398571428571428\n",
      "Model 55 Test set accuracy: 0.6304285714285714\n",
      "Model 56 Test set accuracy: 0.6008571428571429\n",
      "Model 57 Test set accuracy: 0.5865714285714285\n",
      "Model 58 Test set accuracy: 0.6162857142857143\n",
      "Model 59 Test set accuracy: 0.6188571428571429\n",
      "Model 60 Test set accuracy: 0.5998571428571429\n",
      "Model 61 Test set accuracy: 0.59\n",
      "Model 62 Test set accuracy: 0.6232857142857143\n",
      "Model 63 Test set accuracy: 0.5828571428571429\n",
      "Model 64 Test set accuracy: 0.4847142857142857\n",
      "Model 65 Test set accuracy: 0.6405714285714286\n",
      "Model 66 Test set accuracy: 0.592\n",
      "Model 67 Test set accuracy: 0.5957142857142858\n",
      "Model 68 Test set accuracy: 0.6401428571428571\n",
      "Model 69 Test set accuracy: 0.5698571428571428\n",
      "Model 70 Test set accuracy: 0.601\n",
      "Model 71 Test set accuracy: 0.5518571428571428\n",
      "Model 72 Test set accuracy: 0.6232857142857143\n",
      "Model 73 Test set accuracy: 0.593\n",
      "Model 74 Test set accuracy: 0.6024285714285714\n",
      "Model 75 Test set accuracy: 0.5698571428571428\n",
      "Model 76 Test set accuracy: 0.6221428571428571\n",
      "Model 77 Test set accuracy: 0.6461428571428571\n",
      "Model 78 Test set accuracy: 0.5944285714285714\n",
      "Model 79 Test set accuracy: 0.6208571428571429\n",
      "Model 80 Test set accuracy: 0.6234285714285714\n",
      "Model 81 Test set accuracy: 0.671\n",
      "Model 82 Test set accuracy: 0.6168571428571429\n",
      "Model 83 Test set accuracy: 0.6247142857142857\n",
      "Model 84 Test set accuracy: 0.6344285714285715\n",
      "Model 85 Test set accuracy: 0.5757142857142857\n",
      "Model 86 Test set accuracy: 0.5604285714285714\n",
      "Model 87 Test set accuracy: 0.5835714285714285\n",
      "Model 88 Test set accuracy: 0.6051428571428571\n",
      "Model 89 Test set accuracy: 0.5965714285714285\n",
      "Model 90 Test set accuracy: 0.5584285714285714\n",
      "Model 91 Test set accuracy: 0.6052857142857143\n",
      "Model 92 Test set accuracy: 0.5848571428571429\n",
      "Model 93 Test set accuracy: 0.5965714285714285\n",
      "Model 94 Test set accuracy: 0.6445714285714286\n",
      "Model 95 Test set accuracy: 0.6374285714285715\n",
      "Model 96 Test set accuracy: 0.6205714285714286\n",
      "Model 97 Test set accuracy: 0.6108571428571429\n",
      "Model 98 Test set accuracy: 0.646\n",
      "Model 99 Test set accuracy: 0.6024285714285714\n",
      "Model 100 Test set accuracy: 0.5908571428571429\n",
      "Model 101 Test set accuracy: 0.6024285714285714\n",
      "Model 102 Test set accuracy: 0.5821428571428572\n",
      "Model 103 Test set accuracy: 0.5781428571428572\n",
      "Model 104 Test set accuracy: 0.57\n",
      "Model 105 Test set accuracy: 0.6568571428571428\n",
      "Model 106 Test set accuracy: 0.5551428571428572\n",
      "Model 107 Test set accuracy: 0.5881428571428572\n",
      "Model 108 Test set accuracy: 0.5608571428571428\n",
      "Model 109 Test set accuracy: 0.6031428571428571\n",
      "Model 110 Test set accuracy: 0.5924285714285714\n",
      "Model 111 Test set accuracy: 0.6298571428571429\n",
      "Model 112 Test set accuracy: 0.5942857142857143\n",
      "Model 113 Test set accuracy: 0.5621428571428572\n",
      "Model 114 Test set accuracy: 0.5867142857142857\n",
      "Model 115 Test set accuracy: 0.624\n",
      "Model 116 Test set accuracy: 0.6165714285714285\n",
      "Model 117 Test set accuracy: 0.6198571428571429\n",
      "Model 118 Test set accuracy: 0.591\n",
      "Model 119 Test set accuracy: 0.6124285714285714\n",
      "Model 120 Test set accuracy: 0.5578571428571428\n",
      "Model 121 Test set accuracy: 0.643\n",
      "Model 122 Test set accuracy: 0.549\n",
      "Model 123 Test set accuracy: 0.6064285714285714\n",
      "Model 124 Test set accuracy: 0.5522857142857143\n",
      "Model 125 Test set accuracy: 0.6372857142857142\n",
      "Model 126 Test set accuracy: 0.5547142857142857\n",
      "Model 127 Test set accuracy: 0.5421428571428571\n",
      "Model 128 Test set accuracy: 0.6204285714285714\n",
      "Model 129 Test set accuracy: 0.5942857142857143\n",
      "Model 130 Test set accuracy: 0.5748571428571428\n",
      "Model 131 Test set accuracy: 0.588\n",
      "Model 132 Test set accuracy: 0.6074285714285714\n",
      "Model 133 Test set accuracy: 0.5977142857142858\n",
      "Model 134 Test set accuracy: 0.5987142857142858\n",
      "Model 135 Test set accuracy: 0.5985714285714285\n",
      "Model 136 Test set accuracy: 0.5861428571428572\n",
      "Model 137 Test set accuracy: 0.6238571428571429\n",
      "Model 138 Test set accuracy: 0.6088571428571429\n",
      "Model 139 Test set accuracy: 0.6185714285714285\n",
      "Model 140 Test set accuracy: 0.5915714285714285\n",
      "Model 141 Test set accuracy: 0.5915714285714285\n",
      "Model 142 Test set accuracy: 0.6071428571428571\n",
      "Model 143 Test set accuracy: 0.604\n",
      "Model 144 Test set accuracy: 0.5768571428571428\n",
      "Model 145 Test set accuracy: 0.5665714285714286\n",
      "Model 146 Test set accuracy: 0.5771428571428572\n",
      "Model 147 Test set accuracy: 0.644\n",
      "Model 148 Test set accuracy: 0.6195714285714286\n",
      "Model 149 Test set accuracy: 0.5628571428571428\n",
      "Model 150 Test set accuracy: 0.5974285714285714\n",
      "Model 151 Test set accuracy: 0.6372857142857142\n",
      "Model 152 Test set accuracy: 0.5808571428571428\n",
      "Model 153 Test set accuracy: 0.5878571428571429\n",
      "Model 154 Test set accuracy: 0.5442857142857143\n",
      "Model 155 Test set accuracy: 0.634\n",
      "Model 156 Test set accuracy: 0.6321428571428571\n",
      "Model 157 Test set accuracy: 0.6292857142857143\n",
      "Model 158 Test set accuracy: 0.6101428571428571\n",
      "Model 159 Test set accuracy: 0.5878571428571429\n",
      "Model 160 Test set accuracy: 0.5882857142857143\n",
      "Model 161 Test set accuracy: 0.5837142857142857\n",
      "Model 162 Test set accuracy: 0.6288571428571429\n",
      "Model 163 Test set accuracy: 0.6401428571428571\n",
      "Model 164 Test set accuracy: 0.5058571428571429\n",
      "Model 165 Test set accuracy: 0.6011428571428571\n",
      "Model 166 Test set accuracy: 0.6338571428571429\n",
      "Model 167 Test set accuracy: 0.5904285714285714\n",
      "Model 168 Test set accuracy: 0.6234285714285714\n",
      "Model 169 Test set accuracy: 0.6131428571428571\n",
      "Model 170 Test set accuracy: 0.623\n",
      "Model 171 Test set accuracy: 0.5442857142857143\n",
      "Model 172 Test set accuracy: 0.6377142857142857\n",
      "Model 173 Test set accuracy: 0.6498571428571429\n",
      "Model 174 Test set accuracy: 0.5958571428571429\n",
      "Model 175 Test set accuracy: 0.6072857142857143\n",
      "Model 176 Test set accuracy: 0.5914285714285714\n",
      "Model 177 Test set accuracy: 0.6271428571428571\n",
      "Model 178 Test set accuracy: 0.5701428571428572\n",
      "Model 179 Test set accuracy: 0.6115714285714285\n",
      "Model 180 Test set accuracy: 0.5311428571428571\n",
      "Model 181 Test set accuracy: 0.6381428571428571\n",
      "Model 182 Test set accuracy: 0.6134285714285714\n",
      "Model 183 Test set accuracy: 0.5525714285714286\n",
      "Model 184 Test set accuracy: 0.6301428571428571\n",
      "Model 185 Test set accuracy: 0.6157142857142858\n",
      "Model 186 Test set accuracy: 0.5331428571428571\n",
      "Model 187 Test set accuracy: 0.6435714285714286\n",
      "Model 188 Test set accuracy: 0.6274285714285714\n",
      "Model 189 Test set accuracy: 0.5941428571428572\n",
      "Model 190 Test set accuracy: 0.5741428571428572\n",
      "Model 191 Test set accuracy: 0.5834285714285714\n",
      "Model 192 Test set accuracy: 0.5531428571428572\n",
      "Model 193 Test set accuracy: 0.5835714285714285\n",
      "Model 194 Test set accuracy: 0.6117142857142858\n",
      "Model 195 Test set accuracy: 0.5275714285714286\n",
      "Model 196 Test set accuracy: 0.6401428571428571\n",
      "Model 197 Test set accuracy: 0.4208571428571429\n",
      "Model 198 Test set accuracy: 0.6232857142857143\n",
      "Model 199 Test set accuracy: 0.5685714285714286\n",
      "Test set accuracy: 0.9281428571428572\n"
     ]
    }
   ],
   "source": [
    "prediction = boosting_predict(X_test, all_models, alphas)\n",
    "accuracy = np.count_nonzero(prediction==int64(y_test))/y_test.shape[0]\n",
    "print(\"Test set accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does performance compare with the other approaches?\n",
    "\n",
    "Try out different values of `sample_size`, `num_models` and `max_depth` of the decision tree.\n",
    "\n",
    "How does training time vary for each approach as you change these ensemble parameters? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "\n",
    "We trained and visualised a decision tree classifier, which showed how decision trees can provide an interpretable model for classification. We then implemented bagging to improve performance, then extended it to the Random Forest and Boosting methods. This should give some idea of how these three key ensemble methods are related to one another. Random Forest adds random sampling over features, while boosting re-weights the dataset at each iteration to focus on misclassified data points.\n",
    "\n",
    "### References\n",
    "- COMS30035 Machine Learning lecture notes.\n",
    "- Bishop Pattern Recognition and Machine Learning: Chapter 14.\n",
    "\n",
    "#### Materials used to create the lab\n",
    "- https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python/blob/master/Chapter%204%20-%20Classification/Exercise%2042%20-%20Iris%20Classification%20Using%20a%20CART%20Decision%20Tree.ipynb\n",
    "- https://plsms.github.io/kaggle/learn/2%20Machine%20Learning/Level%201/11%20Exercise;%20Random%20Forests.html\n",
    "- https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c\n",
    "- https://www.kaggle.com/jmohitj/practicing-playing-with-mnist-decision-tree\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
